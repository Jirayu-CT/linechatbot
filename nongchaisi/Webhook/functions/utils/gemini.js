const { GoogleGenerativeAI } = require("@google/generative-ai");
const genAI = new GoogleGenerativeAI(process.env.API_KEY);

class Gemini {
    async chat(cacheChatHistory, prompt) {
        // Note: From Nov 2024, the model has changed to gemini-1.5-flash for mutimodal compatible
        const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
        const chatHistory = [
            {
                role: "user",
                parts: [{ text: "à¸ªà¸§à¸±à¸ªà¸”à¸µ à¸„à¸¸à¸“à¸ªà¸²à¸¡à¸²à¸£à¸–à¸Šà¹ˆà¸§à¸¢à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡à¸‚à¸­à¸‡à¸‰à¸±à¸™à¹„à¸”à¹‰à¹„à¸«à¸¡?" }]
            },
            {
                role: "model",
                parts: [{ text: "à¹à¸™à¹ˆà¸™à¸­à¸™! à¸–à¸²à¸¡à¸¡à¸²à¹„à¸”à¹‰à¹€à¸¥à¸¢à¸„à¸£à¸±à¸š ðŸ˜Š" }]
            }
        ];
        if (cacheChatHistory.length > 0) {
            chatHistory.push(...cacheChatHistory);
        }
        const chat = model.startChat({ history: chatHistory });
        const result = await chat.sendMessage(prompt);
        return result.response.text();
    }
}

module.exports = new Gemini();